{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67591ad8",
   "metadata": {},
   "source": [
    "# Практические задания к лекции № 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dbd24a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "33bd6f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, roc_auc_score, precision_score, classification_report, precision_recall_curve, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41990252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>Заместитель председателяnправительства РФnСерг...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4896</td>\n",
       "      <td>Матч 1/16 финала Кубка России по футболу был п...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4897</td>\n",
       "      <td>Форвард «Авангарда» Томаш Заборский прокоммент...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   doc_id                                              title\n",
       "0       6  Заместитель председателяnправительства РФnСерг...\n",
       "1    4896  Матч 1/16 финала Кубка России по футболу был п...\n",
       "2    4897  Форвард «Авангарда» Томаш Заборский прокоммент..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news = pd.read_csv(\"articles.csv\")\n",
    "print(news.shape)\n",
    "news.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc0814ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.corpora.dictionary import Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6bf05696",
   "metadata": {},
   "outputs": [],
   "source": [
    "#предобработка текстов\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "#from nltk.tokenize import word_tokenize\n",
    "\n",
    "from razdel import tokenize # https://github.com/natasha/razdel\n",
    "import pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46e84e68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\pvs-v\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "450df4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword_ru = stopwords.words('russian')\n",
    "\n",
    "morph = pymorphy2.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "496693a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "776"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('stopwords.txt') as f:\n",
    "    additional_stopwords = [w.strip() for w in f.readlines() if w]\n",
    "stopword_ru += additional_stopwords\n",
    "len(stopword_ru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "473c4589",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    '''\n",
    "    очистка текста\n",
    "    \n",
    "    на выходе очищеный текст\n",
    "    \n",
    "    '''\n",
    "    if not isinstance(text, str):\n",
    "        text = str(text)\n",
    "    \n",
    "    text = text.lower()\n",
    "    text = text.strip('\\n').strip('\\r').strip('\\t')\n",
    "    text = re.sub(\"-\\s\\r\\n\\|-\\s\\r\\n|\\r\\n\", '', str(text))\n",
    "\n",
    "    text = re.sub(\"[0-9]|[-—.,:;_%©«»?*!@#№$^•·&()]|[+=]|[[]|[]]|[/]|\", '', text)\n",
    "    text = re.sub(r\"\\r\\n\\t|\\n|\\\\s|\\r\\t|\\\\n\", ' ', text)\n",
    "    text = re.sub(r'[\\xad]|[\\s+]', ' ', text.strip())\n",
    "    \n",
    "    #tokens = list(tokenize(text))\n",
    "    #words = [_.text for _ in tokens]\n",
    "    #words = [w for w in words if w not in stopword_ru]\n",
    "    \n",
    "    #return \" \".join(words)\n",
    "    return text\n",
    "\n",
    "cache = {}\n",
    "\n",
    "def lemmatization(text):\n",
    "    '''\n",
    "    лемматизация\n",
    "        [0] если зашел тип не `str` делаем его `str`\n",
    "        [1] токенизация предложения через razdel\n",
    "        [2] проверка есть ли в начале слова '-'\n",
    "        [3] проверка токена с одного символа\n",
    "        [4] проверка есть ли данное слово в кэше\n",
    "        [5] лемматизация слова\n",
    "        [6] проверка на стоп-слова\n",
    "\n",
    "    на выходе лист отлемматизированых токенов\n",
    "    '''\n",
    "\n",
    "    # [0]\n",
    "    if not isinstance(text, str):\n",
    "        text = str(text)\n",
    "    \n",
    "    # [1]\n",
    "    tokens = list(tokenize(text))\n",
    "    words = [_.text for _ in tokens]\n",
    "\n",
    "    words_lem = []\n",
    "    for w in words:\n",
    "        if w[0] == '-': # [2]\n",
    "            w = w[1:]\n",
    "        if len(w)>1: # [3]\n",
    "            if w in cache: # [4]\n",
    "                words_lem.append(cache[w])\n",
    "            else: # [5]\n",
    "                temp_cach = cache[w] = morph.parse(w)[0].normal_form\n",
    "                words_lem.append(temp_cach)\n",
    "    \n",
    "    words_lem_without_stopwords=[i for i in words_lem if not i in stopword_ru] # [6]\n",
    "    \n",
    "    return words_lem_without_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe2b87a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-7ee348d9b386>:15: FutureWarning: Possible nested set at position 39\n",
      "  text = re.sub(\"[0-9]|[-—.,:;_%©«»?*!@#№$^•·&()]|[+=]|[[]|[]]|[/]|\", '', text)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 16.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Запускаем очистку текста. \n",
    "news['title'] = news['title'].apply(lambda x: clean_text(x), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c11eabed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Запускаем лемматизацию текста. Будет очень долго...\n",
    "news['title'] = news['title'].apply(lambda x: lemmatization(x), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c98e9cc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [заместитель, председатель, правительство, рф,...\n",
       "1        [матч, финал, кубок, россия, футбол, приостано...\n",
       "2        [форвард, авангард, томаш, заборский, прокомме...\n",
       "3        [главный, тренер, кубань, юрий, красножанин, п...\n",
       "4        [решение, попечительский, совет, владивостокск...\n",
       "                               ...                        \n",
       "26995    [учёный, токийский, университет, морской, наук...\n",
       "26996    [глава, кафедра, отечественный, история, xx, в...\n",
       "26997    [американский, учёный, уточнить, возраст, расп...\n",
       "26998    [последний, год, тропический, углеродный, цикл...\n",
       "26999    [жить, примерно, тыс, год, назад, территория, ...\n",
       "Name: title, Length: 27000, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0098a264",
   "metadata": {},
   "outputs": [],
   "source": [
    "#сформируем список наших текстов, разбив еще и на пробелы\n",
    "texts = [t for t in news['title'].values]\n",
    "\n",
    "# Create a corpus from a list of texts\n",
    "common_dictionary = Dictionary(texts)\n",
    "common_corpus = [common_dictionary.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7541c13f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ватутин'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_dictionary[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "38d54f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import LdaModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a9169094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from gensim.models import LdaModel\n",
    "# Train the model on the corpus.\n",
    "lda = LdaModel(common_corpus, num_topics=25, id2word=common_dictionary, passes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f930121b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import datapath\n",
    "# Save model to disk.\n",
    "temp_file = datapath(\"model.lda\")\n",
    "lda.save(temp_file)\n",
    "\n",
    "# Load a potentially pretrained model from disk.\n",
    "lda = LdaModel.load(temp_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "257c7263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['форвард', 'авангард', 'томаш', 'заборский', 'прокомментировать', 'игра', 'свой', 'команда', 'матч', 'чемпионат', 'кхл', 'против', 'атланта', 'nnnn', 'провести', 'плохой', 'матч', 'нижний', 'новгород', 'против', 'торпедо', 'настраиваться', 'первый', 'минута', 'включиться', 'работа', 'сказать', 'заборский', 'получиться', 'забросить', 'быстрый', 'гол', 'задать', 'хороший', 'темп', 'поединок', 'мочь', 'играть', 'ещё', 'хороший', 'сторона', 'пять', 'очко', 'выезд', 'девять', 'это', 'хороший']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0, 0.26950175),\n",
       " (3, 0.018455738),\n",
       " (4, 0.061357517),\n",
       " (7, 0.163757),\n",
       " (9, 0.033353053),\n",
       " (10, 0.18925849),\n",
       " (13, 0.21837434),\n",
       " (15, 0.031118033)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new corpus, made of previously unseen documents.\n",
    "other_texts = [t for t in news['title'].iloc[:3]]\n",
    "other_corpus = [common_dictionary.doc2bow(text) for text in other_texts]\n",
    "\n",
    "unseen_doc = other_corpus[2]\n",
    "print(other_texts[2])\n",
    "lda[unseen_doc] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "254ce920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic_0: испания команда матч адмирал победа чемпионат арбитраж\n",
      "topic_1: остров армия экипаж километр воздух сигнал флот\n",
      "topic_2: год млн цена рост составить тыс рынок\n",
      "topic_3: век сократиться еда италия образоваться датчик пить\n",
      "topic_4: украина украинский который закон гражданин год право\n",
      "topic_5: депутат совет выплата доход зарплата пост президент\n",
      "topic_6: земля который год время это станция первый\n",
      "topic_7: россия российский млрд москва проект также nn\n",
      "topic_8: египет японский корея япония южный курение актёр\n",
      "topic_9: фотография лёд рисунок дед кит просмотр прага\n",
      "topic_10: год это который человек мочь весь всё\n",
      "topic_11: сша американский журнал китай китайский опубликовать иран\n",
      "topic_12: статья день это человек который всё газета\n",
      "topic_13: женщина обнаружить свой жизнь смерть который мужчина\n",
      "topic_14: военный ракета сила операция советский территория боевой\n",
      "topic_15: форум бизнесмен белый медицина израиль лауреат израильский\n",
      "topic_16: год суд налог место млн nn рейтинг\n",
      "topic_17: товар аэропорт рейс торговый способность клиент перевод\n",
      "topic_18: пенсия турецкий турция вицепремьер климат характерный изучение\n",
      "topic_19: человек произойти погибнуть тело который находиться результат\n",
      "topic_20: это страна россия президент заявить который свой\n",
      "topic_21: nn год исследование стать который первый новый\n",
      "topic_22: музыка снаряд чешский вечный чехия неполадка запорожский\n",
      "topic_23: год это который мочь газ риск выяснить\n",
      "topic_24: компания банк фонд дело рубль который это\n"
     ]
    }
   ],
   "source": [
    "x=lda.show_topics(num_topics=25, num_words=7,formatted=False)\n",
    "topics_words = [(tp[0], [wd[0] for wd in tp[1]]) for tp in x]\n",
    "\n",
    "#Below Code Prints Only Words \n",
    "for topic,words in topics_words:\n",
    "    print(\"topic_{}: \".format(topic)+\" \".join(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "09cc01ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lda_vector(text):\n",
    "    unseen_doc = common_dictionary.doc2bow(text)\n",
    "    lda_tuple = lda[unseen_doc]\n",
    "    not_null_topics = dict(zip([i[0] for i in lda_tuple], [i[1] for i in lda_tuple]))\n",
    "\n",
    "    output_vector = []\n",
    "    for i in range(25):\n",
    "        if i not in not_null_topics:\n",
    "            output_vector.append(0)\n",
    "        else:\n",
    "            output_vector.append(not_null_topics[i])\n",
    "    return np.array(output_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a823e9db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>topic_0</th>\n",
       "      <th>topic_1</th>\n",
       "      <th>topic_2</th>\n",
       "      <th>topic_3</th>\n",
       "      <th>topic_4</th>\n",
       "      <th>topic_5</th>\n",
       "      <th>topic_6</th>\n",
       "      <th>topic_7</th>\n",
       "      <th>topic_8</th>\n",
       "      <th>...</th>\n",
       "      <th>topic_15</th>\n",
       "      <th>topic_16</th>\n",
       "      <th>topic_17</th>\n",
       "      <th>topic_18</th>\n",
       "      <th>topic_19</th>\n",
       "      <th>topic_20</th>\n",
       "      <th>topic_21</th>\n",
       "      <th>topic_22</th>\n",
       "      <th>topic_23</th>\n",
       "      <th>topic_24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>0.030858</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020795</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.585876</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013306</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.100472</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.241952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4896</td>\n",
       "      <td>0.331076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.238438</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.061268</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.052532</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4897</td>\n",
       "      <td>0.269532</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018448</td>\n",
       "      <td>0.061263</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.163845</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031117</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4898</td>\n",
       "      <td>0.127632</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027717</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.17769</td>\n",
       "      <td>0.162184</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.181681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4899</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.291623</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.067208</td>\n",
       "      <td>0.433246</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.064401</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.121271</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   doc_id   topic_0  topic_1   topic_2   topic_3   topic_4   topic_5  \\\n",
       "0       6  0.030858      0.0  0.000000  0.000000  0.000000  0.020795   \n",
       "1    4896  0.331076      0.0  0.238438  0.000000  0.000000  0.000000   \n",
       "2    4897  0.269532      0.0  0.000000  0.018448  0.061263  0.000000   \n",
       "3    4898  0.127632      0.0  0.000000  0.000000  0.000000  0.000000   \n",
       "4    4899  0.000000      0.0  0.291623  0.000000  0.067208  0.433246   \n",
       "\n",
       "    topic_6   topic_7  topic_8  ...  topic_15  topic_16  topic_17  topic_18  \\\n",
       "0  0.000000  0.585876      0.0  ...  0.013306  0.000000       0.0  0.000000   \n",
       "1  0.000000  0.000000      0.0  ...  0.000000  0.061268       0.0  0.000000   \n",
       "2  0.000000  0.163845      0.0  ...  0.031117  0.000000       0.0  0.000000   \n",
       "3  0.027717  0.000000      0.0  ...  0.000000  0.000000       0.0  0.000000   \n",
       "4  0.000000  0.000000      0.0  ...  0.000000  0.000000       0.0  0.064401   \n",
       "\n",
       "   topic_19  topic_20  topic_21  topic_22  topic_23  topic_24  \n",
       "0       0.0   0.00000  0.100472  0.000000       0.0  0.241952  \n",
       "1       0.0   0.00000  0.000000  0.052532       0.0  0.000000  \n",
       "2       0.0   0.00000  0.000000  0.000000       0.0  0.000000  \n",
       "3       0.0   0.17769  0.162184  0.000000       0.0  0.181681  \n",
       "4       0.0   0.00000  0.121271  0.000000       0.0  0.000000  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_matrix = pd.DataFrame([get_lda_vector(text) for text in news['title'].values])\n",
    "topic_matrix.columns = ['topic_{}'.format(i) for i in range(25)]\n",
    "topic_matrix['doc_id'] = news['doc_id'].values\n",
    "topic_matrix = topic_matrix[['doc_id']+['topic_{}'.format(i) for i in range(25)]]\n",
    "topic_matrix.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1504f82e",
   "metadata": {},
   "source": [
    "### Следующий шаг - векторные представления пользователей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eb4a1749",
   "metadata": {},
   "outputs": [],
   "source": [
    "users = pd.read_csv(\"users_articles.csv\")\n",
    "doc_dict = dict(zip(topic_matrix['doc_id'].values, topic_matrix[['topic_{}'.format(i) for i in range(25)]].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f6c7a03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_embedding(user_articles_list):\n",
    "    user_articles_list = eval(user_articles_list)\n",
    "    user_vector = np.array([doc_dict[doc_id] for doc_id in user_articles_list])\n",
    "    user_vector = np.mean(user_vector, 0)\n",
    "    return user_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e3cbef6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>topic_0</th>\n",
       "      <th>topic_1</th>\n",
       "      <th>topic_2</th>\n",
       "      <th>topic_3</th>\n",
       "      <th>topic_4</th>\n",
       "      <th>topic_5</th>\n",
       "      <th>topic_6</th>\n",
       "      <th>topic_7</th>\n",
       "      <th>topic_8</th>\n",
       "      <th>...</th>\n",
       "      <th>topic_15</th>\n",
       "      <th>topic_16</th>\n",
       "      <th>topic_17</th>\n",
       "      <th>topic_18</th>\n",
       "      <th>topic_19</th>\n",
       "      <th>topic_20</th>\n",
       "      <th>topic_21</th>\n",
       "      <th>topic_22</th>\n",
       "      <th>topic_23</th>\n",
       "      <th>topic_24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>u105138</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021200</td>\n",
       "      <td>0.002616</td>\n",
       "      <td>0.151779</td>\n",
       "      <td>0.009287</td>\n",
       "      <td>0.040571</td>\n",
       "      <td>0.107242</td>\n",
       "      <td>0.017113</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007286</td>\n",
       "      <td>0.012240</td>\n",
       "      <td>0.011932</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033149</td>\n",
       "      <td>0.103190</td>\n",
       "      <td>0.222959</td>\n",
       "      <td>0.012822</td>\n",
       "      <td>0.035348</td>\n",
       "      <td>0.014995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>u108690</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.002464</td>\n",
       "      <td>0.032520</td>\n",
       "      <td>0.008659</td>\n",
       "      <td>0.122238</td>\n",
       "      <td>0.028704</td>\n",
       "      <td>0.017315</td>\n",
       "      <td>0.026767</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002353</td>\n",
       "      <td>0.005680</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015792</td>\n",
       "      <td>0.065533</td>\n",
       "      <td>0.254003</td>\n",
       "      <td>0.042296</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.082919</td>\n",
       "      <td>0.057962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>u108339</td>\n",
       "      <td>0.00399</td>\n",
       "      <td>0.007811</td>\n",
       "      <td>0.031273</td>\n",
       "      <td>0.002248</td>\n",
       "      <td>0.056156</td>\n",
       "      <td>0.006662</td>\n",
       "      <td>0.055660</td>\n",
       "      <td>0.099618</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011774</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002959</td>\n",
       "      <td>0.162878</td>\n",
       "      <td>0.145582</td>\n",
       "      <td>0.075016</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.117099</td>\n",
       "      <td>0.061308</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       uid  topic_0   topic_1   topic_2   topic_3   topic_4   topic_5  \\\n",
       "0  u105138  0.00000  0.000000  0.021200  0.002616  0.151779  0.009287   \n",
       "1  u108690  0.00000  0.002464  0.032520  0.008659  0.122238  0.028704   \n",
       "2  u108339  0.00399  0.007811  0.031273  0.002248  0.056156  0.006662   \n",
       "\n",
       "    topic_6   topic_7   topic_8  ...  topic_15  topic_16  topic_17  topic_18  \\\n",
       "0  0.040571  0.107242  0.017113  ...  0.007286  0.012240  0.011932  0.000000   \n",
       "1  0.017315  0.026767  0.000000  ...  0.002353  0.005680  0.000000  0.015792   \n",
       "2  0.055660  0.099618  0.000000  ...  0.000000  0.011774  0.000000  0.002959   \n",
       "\n",
       "   topic_19  topic_20  topic_21  topic_22  topic_23  topic_24  \n",
       "0  0.033149  0.103190  0.222959  0.012822  0.035348  0.014995  \n",
       "1  0.065533  0.254003  0.042296  0.000000  0.082919  0.057962  \n",
       "2  0.162878  0.145582  0.075016  0.000000  0.117099  0.061308  \n",
       "\n",
       "[3 rows x 26 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_embeddings = pd.DataFrame([i for i in users['articles'].apply(lambda x: get_user_embedding(x), 1)])\n",
    "user_embeddings.columns = ['topic_{}'.format(i) for i in range(25)]\n",
    "user_embeddings['uid'] = users['uid'].values\n",
    "user_embeddings = user_embeddings[['uid']+['topic_{}'.format(i) for i in range(25)]]\n",
    "user_embeddings.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "34a99c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = pd.read_csv(\"users_churn.csv\")\n",
    "X = pd.merge(user_embeddings, target, 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e984f6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X[['topic_{}'.format(i) for i in range(25)]], \n",
    "                                                    X['churn'], random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "794fccdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()\n",
    "#обучим \n",
    "logreg.fit(X_train, y_train)\n",
    "preds = logreg.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3c188e38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold=0.366352, F-Score=0.822, Precision=0.902, Recall=0.755\n"
     ]
    }
   ],
   "source": [
    "precision, recall, thresholds = precision_recall_curve(y_test, preds)\n",
    "fscore = (2 * precision * recall) / (precision + recall)\n",
    "# locate the index of the largest f score\n",
    "ix = np.argmax(fscore)\n",
    "print('Best Threshold=%f, F-Score=%.3f, Precision=%.3f, Recall=%.3f' % (thresholds[ix], \n",
    "                                                                        fscore[ix],\n",
    "                                                                        precision[ix],\n",
    "                                                                        recall[ix]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3dfc2023",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9797174254317111,\n",
       " 0.8222222222222222,\n",
       " 0.9024390243902439,\n",
       " 0.7551020408163265]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_mean = [roc_auc_score(y_test, preds), fscore[ix], precision[ix], recall[ix]]\n",
    "scores_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a357936",
   "metadata": {},
   "source": [
    "1. Самостоятельно разобраться с тем, что такое tfidf (документация https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html и еще - https://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae115104",
   "metadata": {},
   "source": [
    "2. Модифицировать код функции get_user_embedding таким образом, чтобы считалось не среднее (как в примере np.mean), а медиана. Применить такое преобразование к данным, обучить модель прогнозирования оттока и посчитать метрики качества и сохранить их: roc auc, precision/recall/f_score (для 3 последних - подобрать оптимальный порог с помощью precision_recall_curve, как это делалось на уроке)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3cce4778",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_embedding(user_articles_list):\n",
    "    user_articles_list = eval(user_articles_list)\n",
    "    user_vector = np.array([doc_dict[doc_id] for doc_id in user_articles_list])\n",
    "    user_vector = np.median(user_vector, 0)\n",
    "    return user_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cd281147",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_embeddings = pd.DataFrame([i for i in users['articles'].apply(lambda x: get_user_embedding(x), 1)])\n",
    "user_embeddings.columns = ['topic_{}'.format(i) for i in range(25)]\n",
    "user_embeddings['uid'] = users['uid'].values\n",
    "user_embeddings = user_embeddings[['uid']+['topic_{}'.format(i) for i in range(25)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6241126d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.merge(user_embeddings, target, 'left')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X[['topic_{}'.format(i) for i in range(25)]], \n",
    "                                                    X['churn'], random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d9471844",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg.fit(X_train, y_train)\n",
    "preds = logreg.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c0cd0d95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold=0.328657, F-Score=0.837, Precision=0.858, Recall=0.816\n"
     ]
    }
   ],
   "source": [
    "precision, recall, thresholds = precision_recall_curve(y_test, preds)\n",
    "fscore = (2 * precision * recall) / (precision + recall)\n",
    "# locate the index of the largest f score\n",
    "ix = np.argmax(fscore)\n",
    "print('Best Threshold=%f, F-Score=%.3f, Precision=%.3f, Recall=%.3f' % (thresholds[ix], \n",
    "                                                                        fscore[ix],\n",
    "                                                                        precision[ix],\n",
    "                                                                        recall[ix]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "08785d4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.98438048723763, 0.8368200836820083, 0.8583690987124464, 0.8163265306122449]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_median = [roc_auc_score(y_test, preds), fscore[ix], precision[ix], recall[ix]]\n",
    "scores_median"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0af6d48",
   "metadata": {},
   "source": [
    "3. Повторить п.2, но используя уже не медиану, а max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d1c811c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_embedding(user_articles_list):\n",
    "    user_articles_list = eval(user_articles_list)\n",
    "    user_vector = np.array([doc_dict[doc_id] for doc_id in user_articles_list])\n",
    "    user_vector = np.max(user_vector, 0)\n",
    "    return user_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3cfaadee",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_embeddings = pd.DataFrame([i for i in users['articles'].apply(lambda x: get_user_embedding(x), 1)])\n",
    "user_embeddings.columns = ['topic_{}'.format(i) for i in range(25)]\n",
    "user_embeddings['uid'] = users['uid'].values\n",
    "user_embeddings = user_embeddings[['uid']+['topic_{}'.format(i) for i in range(25)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "716b92ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.merge(user_embeddings, target, 'left')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X[['topic_{}'.format(i) for i in range(25)]], \n",
    "                                                    X['churn'], random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d5a37334",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg.fit(X_train, y_train)\n",
    "preds = logreg.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "05c3d838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold=0.407572, F-Score=0.812, Precision=0.824, Recall=0.800\n"
     ]
    }
   ],
   "source": [
    "precision, recall, thresholds = precision_recall_curve(y_test, preds)\n",
    "fscore = (2 * precision * recall) / (precision + recall)\n",
    "# locate the index of the largest f score\n",
    "ix = np.argmax(fscore)\n",
    "print('Best Threshold=%f, F-Score=%.3f, Precision=%.3f, Recall=%.3f' % (thresholds[ix], \n",
    "                                                                        fscore[ix],\n",
    "                                                                        precision[ix],\n",
    "                                                                        recall[ix]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "194995d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.978912727484156, 0.8115942028985507, 0.8235294117647058, 0.8]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_max = [roc_auc_score(y_test, preds), fscore[ix], precision[ix], recall[ix]]\n",
    "scores_max"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7796ad34",
   "metadata": {},
   "source": [
    "4. (опциональное, если очень хочется) Воспользовавшись полученными знаниями из п.1, повторить пункт 2, но уже взвешивая новости по tfidf (подсказка: нужно получить веса-коэффициенты для каждого документа. Не все документы одинаково информативны и несут какой-то положительный сигнал). Подсказка 2 - нужен именно idf, как вес."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72deb221",
   "metadata": {},
   "source": [
    "5. Сформировать на выходе единую таблицу, сравнивающую качество 3 разных метода получения эмбедингов пользователей: mean, median, max, idf_mean по метрикам roc_auc, precision, recall, f_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ad7a2e2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <th>fscore</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.979717</td>\n",
       "      <td>0.822222</td>\n",
       "      <td>0.902439</td>\n",
       "      <td>0.755102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median</th>\n",
       "      <td>0.984380</td>\n",
       "      <td>0.836820</td>\n",
       "      <td>0.858369</td>\n",
       "      <td>0.816327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.978913</td>\n",
       "      <td>0.811594</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        roc_auc_score    fscore  precision    recall\n",
       "mean         0.979717  0.822222   0.902439  0.755102\n",
       "median       0.984380  0.836820   0.858369  0.816327\n",
       "max          0.978913  0.811594   0.823529  0.800000"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame([scores_mean, scores_median, scores_max], \n",
    "                  columns = ['roc_auc_score', 'fscore', 'precision', 'recall'], \n",
    "                  index = ['mean', 'median', 'max'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3725b5",
   "metadata": {},
   "source": [
    "6. Сделать самостоятельные выводы и предположения о том, почему тот или ной способ оказался эффективнее остальных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1149d7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9181e868",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab4ca4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
